
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>openmdao.drivers.scipy_optimizer &#8212; OpenMDAO 2.8.0 Beta documentation</title>
    <link rel="stylesheet" href="../../../_static/style.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/OpenMDAO_Favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">OpenMDAO 2.8.0 Beta documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/OpenMDAO_Logo.png" alt="Logo"/>
            </a></p>
<h3><a href="../../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/index.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../basic_guide/index.html">Basic User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced_guide/index.html">Advanced User Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../features/index.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../theory_manual/index.html">Theory Manual</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../other/om_command.html">Command Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/citing.html">How to Cite OpenMDAO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/repo_guide/index.html">Building a Tool on Top of OpenMDAO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/api_translation.html">Upgrading from OpenMDAO 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/file_wrap.html">File Wrapping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_srcdocs/index.html">Source Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer_docs/index.html">Developer Docs (if youâ€™re going to contribute code)</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Search OpenMDAO</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="checkbox" name="search_source" /> Include Source Docs
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for openmdao.drivers.scipy_optimizer</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">OpenMDAO Wrapper for the scipy.optimize.minimize family of local optimizers.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">scipy_version</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">six</span> <span class="k">import</span> <span class="n">itervalues</span><span class="p">,</span> <span class="n">iteritems</span><span class="p">,</span> <span class="n">reraise</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>

<span class="kn">import</span> <span class="nn">openmdao</span>
<span class="kn">import</span> <span class="nn">openmdao.utils.coloring</span> <span class="k">as</span> <span class="nn">coloring_mod</span>
<span class="kn">from</span> <span class="nn">openmdao.core.driver</span> <span class="k">import</span> <span class="n">Driver</span><span class="p">,</span> <span class="n">RecordingDebugging</span>
<span class="kn">from</span> <span class="nn">openmdao.utils.general_utils</span> <span class="k">import</span> <span class="n">warn_deprecation</span>

<span class="c1"># Optimizers in scipy.minimize</span>
<span class="n">_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span> <span class="s1">&#39;Powell&#39;</span><span class="p">,</span> <span class="s1">&#39;CG&#39;</span><span class="p">,</span> <span class="s1">&#39;BFGS&#39;</span><span class="p">,</span> <span class="s1">&#39;Newton-CG&#39;</span><span class="p">,</span> <span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span>
               <span class="s1">&#39;TNC&#39;</span><span class="p">,</span> <span class="s1">&#39;COBYLA&#39;</span><span class="p">,</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">}</span>
<span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">scipy_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s2">&quot;1.1&quot;</span><span class="p">):</span>  <span class="c1"># Only available in newer versions</span>
    <span class="n">_optimizers</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">)</span>

<span class="c1"># For &#39;basinhopping&#39; and &#39;shgo&#39; gradients are used only in the local minimization</span>
<span class="n">_gradient_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;CG&#39;</span><span class="p">,</span> <span class="s1">&#39;BFGS&#39;</span><span class="p">,</span> <span class="s1">&#39;Newton-CG&#39;</span><span class="p">,</span> <span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="s1">&#39;TNC&#39;</span><span class="p">,</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="s1">&#39;dogleg&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;trust-ncg&#39;</span><span class="p">,</span> <span class="s1">&#39;trust-constr&#39;</span><span class="p">,</span> <span class="s1">&#39;basinhopping&#39;</span><span class="p">,</span> <span class="s1">&#39;shgo&#39;</span><span class="p">}</span>
<span class="n">_hessian_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">,</span> <span class="s1">&#39;trust-ncg&#39;</span><span class="p">}</span>
<span class="n">_bounds_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="s1">&#39;TNC&#39;</span><span class="p">,</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="s1">&#39;trust-constr&#39;</span><span class="p">,</span> <span class="s1">&#39;dual_annealing&#39;</span><span class="p">,</span> <span class="s1">&#39;shgo&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;differential_evolution&#39;</span><span class="p">,</span> <span class="s1">&#39;basinhopping&#39;</span><span class="p">}</span>
<span class="n">_constraint_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;COBYLA&#39;</span><span class="p">,</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="s1">&#39;trust-constr&#39;</span><span class="p">,</span> <span class="s1">&#39;shgo&#39;</span><span class="p">}</span>
<span class="n">_constraint_grad_optimizers</span> <span class="o">=</span> <span class="n">_gradient_optimizers</span> <span class="o">&amp;</span> <span class="n">_constraint_optimizers</span>
<span class="n">_eq_constraint_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="s1">&#39;trust-constr&#39;</span><span class="p">}</span>
<span class="n">_global_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;differential_evolution&#39;</span><span class="p">,</span> <span class="s1">&#39;basinhopping&#39;</span><span class="p">}</span>
<span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">scipy_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s2">&quot;1.2&quot;</span><span class="p">):</span>  <span class="c1"># Only available in newer versions</span>
    <span class="n">_global_optimizers</span> <span class="o">|=</span> <span class="p">{</span><span class="s1">&#39;shgo&#39;</span><span class="p">,</span> <span class="s1">&#39;dual_annealing&#39;</span><span class="p">}</span>

<span class="c1"># Global optimizers and optimizers in minimize</span>
<span class="n">_all_optimizers</span> <span class="o">=</span> <span class="n">_optimizers</span> <span class="o">|</span> <span class="n">_global_optimizers</span>

<span class="c1"># These require Hessian or Hessian-vector product, so they are not supported</span>
<span class="c1"># right now.</span>
<span class="c1"># dual-annealing and basinhopping not supported yet</span>
<span class="n">_unsupported_optimizers</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;dogleg&#39;</span><span class="p">,</span> <span class="s1">&#39;trust-ncg&#39;</span><span class="p">}</span>

<span class="c1"># With &quot;old-style&quot; a constraint is a dictionary, with &quot;new-style&quot; an object</span>
<span class="c1"># With &quot;old-style&quot; a bound is a tuple, with &quot;new-style&quot; a Bounds instance</span>
<span class="c1"># In principle now everything can work with &quot;old-style&quot;</span>
<span class="c1"># These settings have no effect to the optimizers implemented before SciPy 1.1</span>
<span class="n">_supports_new_style</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;trust-constr&#39;</span><span class="p">}</span>
<span class="n">_use_new_style</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Recommended to set to True</span>

<span class="n">CITATIONS</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">@article{Hwang_maud_2018</span>
<span class="s2"> author = {Hwang, John T. and Martins, Joaquim R.R.A.},</span>
<span class="s2"> title = &quot;{A Computational Architecture for Coupling Heterogeneous</span>
<span class="s2">          Numerical Models and Computing Coupled Derivatives}&quot;,</span>
<span class="s2"> journal = &quot;{ACM Trans. Math. Softw.}&quot;,</span>
<span class="s2"> volume = </span><span class="si">{44}</span><span class="s2">,</span>
<span class="s2"> number = </span><span class="si">{4}</span><span class="s2">,</span>
<span class="s2"> month = jun,</span>
<span class="s2"> year = </span><span class="si">{2018}</span><span class="s2">,</span>
<span class="s2"> pages = {37:1--37:39},</span>
<span class="s2"> articleno = </span><span class="si">{37}</span><span class="s2">,</span>
<span class="s2"> numpages = </span><span class="si">{39}</span><span class="s2">,</span>
<span class="s2"> doi = {10.1145/3182393},</span>
<span class="s2"> publisher = </span><span class="si">{ACM}</span><span class="s2">,</span>
<span class="s2">&quot;&quot;&quot;</span>


<div class="viewcode-block" id="ScipyOptimizeDriver"><a class="viewcode-back" href="../../../_srcdocs/packages/drivers/scipy_optimizer.html#openmdao.drivers.scipy_optimizer.ScipyOptimizeDriver">[docs]</a><span class="k">class</span> <span class="nc">ScipyOptimizeDriver</span><span class="p">(</span><span class="n">Driver</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Driver wrapper for the scipy.optimize.minimize family of local optimizers.</span>

<span class="sd">    Inequality constraints are supported by COBYLA and SLSQP,</span>
<span class="sd">    but equality constraints are only supported by SLSQP. None of the other</span>
<span class="sd">    optimizers support constraints.</span>

<span class="sd">    ScipyOptimizeDriver supports the following:</span>
<span class="sd">        equality_constraints</span>
<span class="sd">        inequality_constraints</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    fail : bool</span>
<span class="sd">        Flag that indicates failure of most recent optimization.</span>
<span class="sd">    iter_count : int</span>
<span class="sd">        Counter for function evaluations.</span>
<span class="sd">    result : OptimizeResult</span>
<span class="sd">        Result returned from scipy.optimize call.</span>
<span class="sd">    opt_settings : dict</span>
<span class="sd">        Dictionary of solver-specific options. See the scipy.optimize.minimize documentation.</span>
<span class="sd">    _con_cache : OrderedDict</span>
<span class="sd">        Cached result of constraint evaluations because scipy asks for them in a separate function.</span>
<span class="sd">    _con_idx : dict</span>
<span class="sd">        Used for constraint bookkeeping in the presence of 2-sided constraints.</span>
<span class="sd">    _grad_cache : OrderedDict</span>
<span class="sd">        Cached result of nonlinear constraint derivatives because scipy asks for them in a separate</span>
<span class="sd">        function.</span>
<span class="sd">    _exc_info : 3 item tuple</span>
<span class="sd">        Storage for exception and traceback information.</span>
<span class="sd">    _obj_and_nlcons : list</span>
<span class="sd">        List of objective + nonlinear constraints. Used to compute total derivatives</span>
<span class="sd">        for all except linear constraints.</span>
<span class="sd">    _dvlist : list</span>
<span class="sd">        Copy of _designvars.</span>
<span class="sd">    _lincongrad_cache : np.ndarray</span>
<span class="sd">        Pre-calculated gradients of linear constraints.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ScipyOptimizeDriver.__init__"><a class="viewcode-back" href="../../../_srcdocs/packages/drivers/scipy_optimizer.html#openmdao.drivers.scipy_optimizer.ScipyOptimizeDriver.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the ScipyOptimizeDriver.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        **kwargs : dict of keyword arguments</span>
<span class="sd">            Keyword arguments that will be mapped into the Driver options.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ScipyOptimizeDriver</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># What we support</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;inequality_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;equality_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;two_sided_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;linear_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;simultaneous_derivatives&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># What we don&#39;t support</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;multiple_objectives&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;active_set&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;integer_design_vars&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># The user places optimizer-specific settings in here.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_grad_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_con_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_con_idx</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obj_and_nlcons</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dvlist</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lincongrad_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fail</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cite</span> <span class="o">=</span> <span class="n">CITATIONS</span></div>

    <span class="k">def</span> <span class="nf">_declare_options</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Declare options before kwargs are processed in the init method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">_all_optimizers</span><span class="p">,</span>
                             <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Name of optimizer to use&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s1">&#39;tol&#39;</span><span class="p">,</span> <span class="mf">1.0e-6</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                             <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Tolerance for termination. For detailed &#39;</span>
                             <span class="s1">&#39;control, use solver-specific options.&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s1">&#39;maxiter&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Maximum number of iterations.&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s1">&#39;disp&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
                             <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Set to False to prevent printing of Scipy convergence messages&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s1">&#39;dynamic_simul_derivs&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
                             <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Compute simultaneous derivative coloring dynamically if True &#39;</span>
                             <span class="s1">&#39;(deprecated)&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s1">&#39;dynamic_derivs_repeats&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">types</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                             <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Number of compute_totals calls during dynamic computation of &#39;</span>
                                  <span class="s1">&#39;simultaneous derivative coloring&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get name of current optimizer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        str</span>
<span class="sd">            The name of the current optimizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;ScipyOptimize_&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;optimizer&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_setup_driver</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">problem</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare the driver for execution.</span>

<span class="sd">        This is the final thing to run during setup.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        problem : &lt;Problem&gt;</span>
<span class="sd">            Pointer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ScipyOptimizeDriver</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_setup_driver</span><span class="p">(</span><span class="n">problem</span><span class="p">)</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;optimizer&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;gradients&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_gradient_optimizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;inequality_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_constraint_optimizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;two_sided_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_constraint_optimizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;equality_constraints&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_eq_constraint_optimizers</span>

        <span class="c1"># Raises error if multiple objectives are not supported, but more objectives were defined.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">supports</span><span class="p">[</span><span class="s1">&#39;multiple_objectives&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_objs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> currently does not support multiple objectives.&#39;</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">msginfo</span><span class="p">))</span>

        <span class="c1"># Since COBYLA does not support bounds, we</span>
        <span class="c1">#   need to add to the _cons metadata for any bounds that</span>
        <span class="c1">#   need to be translated into a constraint</span>
        <span class="k">if</span> <span class="n">opt</span> <span class="o">==</span> <span class="s1">&#39;COBYLA&#39;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">iteritems</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_designvars</span><span class="p">):</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">]</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;upper&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="n">lower</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">openmdao</span><span class="o">.</span><span class="n">INF_BOUND</span> \
                        <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="n">upper</span> <span class="o">&lt;=</span> <span class="n">openmdao</span><span class="o">.</span><span class="n">INF_BOUND</span><span class="p">:</span>
                    <span class="n">d</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lower</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;upper&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">upper</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;equals&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;indices&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;adder&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;scaler&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span>
                    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_cons</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span>

<div class="viewcode-block" id="ScipyOptimizeDriver.run"><a class="viewcode-back" href="../../../_srcdocs/packages/drivers/scipy_optimizer.html#openmdao.drivers.scipy_optimizer.ScipyOptimizeDriver.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Optimize the problem using selected Scipy optimizer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        boolean</span>
<span class="sd">            Failure flag; True if failed to converge, False is successful.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">problem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_problem</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;optimizer&#39;</span><span class="p">]</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_total_jac</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_for_missing_objective</span><span class="p">()</span>

        <span class="c1"># Initial Run</span>
        <span class="k">with</span> <span class="n">RecordingDebugging</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_name</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_count</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span> <span class="k">as</span> <span class="n">rec</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">run_solve_nonlinear</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iter_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_con_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_constraint_values</span><span class="p">()</span>
        <span class="n">desvar_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_design_var_values</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dvlist</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_designvars</span><span class="p">)</span>

        <span class="c1"># maxiter and disp get passsed into scipy with all the other options.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;maxiter&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span>

        <span class="c1"># Size Problem</span>
        <span class="n">nparam</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">itervalues</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_designvars</span><span class="p">):</span>
            <span class="n">nparam</span> <span class="o">+=</span> <span class="n">param</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span>
        <span class="n">x_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nparam</span><span class="p">)</span>

        <span class="c1"># Initial Design Vars</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">use_bounds</span> <span class="o">=</span> <span class="p">(</span><span class="n">opt</span> <span class="ow">in</span> <span class="n">_bounds_optimizers</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_bounds</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">iteritems</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_designvars</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span>
            <span class="n">x_init</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">size</span><span class="p">]</span> <span class="o">=</span> <span class="n">desvar_vals</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="n">size</span>

            <span class="c1"># Bounds if our optimizer supports them</span>
            <span class="k">if</span> <span class="n">use_bounds</span><span class="p">:</span>
                <span class="n">meta_low</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">]</span>
                <span class="n">meta_high</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;upper&#39;</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>

                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_low</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                        <span class="n">p_low</span> <span class="o">=</span> <span class="n">meta_low</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p_low</span> <span class="o">=</span> <span class="n">meta_low</span>

                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_high</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                        <span class="n">p_high</span> <span class="o">=</span> <span class="n">meta_high</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p_high</span> <span class="o">=</span> <span class="n">meta_high</span>

                    <span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">p_low</span><span class="p">,</span> <span class="n">p_high</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">use_bounds</span> <span class="ow">and</span> <span class="p">(</span><span class="n">opt</span> <span class="ow">in</span> <span class="n">_supports_new_style</span><span class="p">)</span> <span class="ow">and</span> <span class="n">_use_new_style</span><span class="p">:</span>
            <span class="c1"># For &#39;trust-constr&#39; it is better to use the new type bounds, because it seems to work</span>
            <span class="c1"># better (for the current examples in the tests) with the &quot;keep_feasible&quot; option</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">Bounds</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize._constraints</span> <span class="k">import</span> <span class="n">old_bound_to_new</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;The &quot;trust-constr&quot; optimizer is supported for SciPy 1.1.0 and above. &#39;</span>
                       <span class="s1">&#39;The installed version is </span><span class="si">{}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scipy_version</span><span class="p">))</span>

            <span class="c1"># Convert &quot;old-style&quot; bounds to &quot;new_style&quot; bounds</span>
            <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">old_bound_to_new</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span>  <span class="c1"># tuple, tuple</span>
            <span class="n">keep_feasible</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;keep_feasible_bounds&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="n">Bounds</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="n">lower</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">upper</span><span class="p">,</span> <span class="n">keep_feasible</span><span class="o">=</span><span class="n">keep_feasible</span><span class="p">)</span>

        <span class="c1"># Constraints</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># start at 1 since row 0 is the objective.  Constraints start at row 1.</span>
        <span class="n">lin_i</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># counter for linear constraint jacobian</span>
        <span class="n">lincons</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># list of linear constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obj_and_nlcons</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_objs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_constraint_optimizers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">iteritems</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cons</span><span class="p">):</span>
                <span class="n">size</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;upper&#39;</span><span class="p">]</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">]</span>
                <span class="n">equals</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;equals&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="s1">&#39;linear&#39;</span> <span class="ow">in</span> <span class="n">meta</span> <span class="ow">and</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]:</span>
                    <span class="n">lincons</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_con_idx</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">lin_i</span>
                    <span class="n">lin_i</span> <span class="o">+=</span> <span class="n">size</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_obj_and_nlcons</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_con_idx</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="n">size</span>

                <span class="c1"># In scipy constraint optimizers take constraints in two separate formats</span>

                <span class="c1"># Type of constraints is list of NonlinearConstraint</span>
                <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_supports_new_style</span> <span class="ow">and</span> <span class="n">_use_new_style</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">NonlinearConstraint</span>
                    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;The &quot;trust-constr&quot; optimizer is supported for SciPy 1.1.0 and&#39;</span>
                               <span class="s1">&#39;above. The installed version is </span><span class="si">{}</span><span class="s1">&#39;</span><span class="p">)</span>
                        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scipy_version</span><span class="p">))</span>

                    <span class="k">if</span> <span class="n">equals</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">lb</span> <span class="o">=</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">equals</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">lb</span> <span class="o">=</span> <span class="n">lower</span>
                        <span class="n">ub</span> <span class="o">=</span> <span class="n">upper</span>
                    <span class="c1"># Loop over every index separately,</span>
                    <span class="c1"># because scipy calls each constraint by index.</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
                        <span class="c1"># Double-sided constraints are accepted by the algorithm</span>
                        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                        <span class="c1"># TODO linear constraint if meta[&#39;linear&#39;]</span>
                        <span class="c1"># TODO add option for Hessian</span>
                        <span class="n">con</span> <span class="o">=</span> <span class="n">NonlinearConstraint</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">signature_extender</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_con_val_func</span><span class="p">,</span> <span class="n">args</span><span class="p">),</span>
                                                  <span class="n">lb</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">ub</span><span class="p">,</span>
                                                  <span class="n">jac</span><span class="o">=</span><span class="n">signature_extender</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_congradfunc</span><span class="p">,</span> <span class="n">args</span><span class="p">))</span>
                        <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">con</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># Type of constraints is list of dict</span>
                    <span class="c1"># Loop over every index separately,</span>
                    <span class="c1"># because scipy calls each constraint by index.</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
                        <span class="n">con_dict</span> <span class="o">=</span> <span class="p">{}</span>
                        <span class="k">if</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;equals&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">con_dict</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;eq&#39;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">con_dict</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ineq&#39;</span>
                        <span class="n">con_dict</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_confunc</span>
                        <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_constraint_grad_optimizers</span><span class="p">:</span>
                            <span class="n">con_dict</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_congradfunc</span>
                        <span class="n">con_dict</span><span class="p">[</span><span class="s1">&#39;args&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                        <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">con_dict</span><span class="p">)</span>

                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                            <span class="n">upper</span> <span class="o">=</span> <span class="n">upper</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                            <span class="n">lower</span> <span class="o">=</span> <span class="n">lower</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                        <span class="n">dblcon</span> <span class="o">=</span> <span class="p">(</span><span class="n">upper</span> <span class="o">&lt;</span> <span class="n">openmdao</span><span class="o">.</span><span class="n">INF_BOUND</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">lower</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">openmdao</span><span class="o">.</span><span class="n">INF_BOUND</span><span class="p">)</span>

                        <span class="c1"># Add extra constraint if double-sided</span>
                        <span class="k">if</span> <span class="n">dblcon</span><span class="p">:</span>
                            <span class="n">dcon_dict</span> <span class="o">=</span> <span class="p">{}</span>
                            <span class="n">dcon_dict</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ineq&#39;</span>
                            <span class="n">dcon_dict</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_confunc</span>
                            <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_constraint_grad_optimizers</span><span class="p">:</span>
                                <span class="n">dcon_dict</span><span class="p">[</span><span class="s1">&#39;jac&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_congradfunc</span>
                            <span class="n">dcon_dict</span><span class="p">[</span><span class="s1">&#39;args&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                            <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dcon_dict</span><span class="p">)</span>

            <span class="c1"># precalculate gradients of linear constraints</span>
            <span class="k">if</span> <span class="n">lincons</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_lincongrad_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_totals</span><span class="p">(</span><span class="n">of</span><span class="o">=</span><span class="n">lincons</span><span class="p">,</span> <span class="n">wrt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dvlist</span><span class="p">,</span>
                                                              <span class="n">return_format</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_lincongrad_cache</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Provide gradients for optimizers that support it</span>
        <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_gradient_optimizers</span><span class="p">:</span>
            <span class="n">jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradfunc</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">jac</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Hessian calculation method for optimizers, which require it</span>
        <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_hessian_optimizers</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;hess&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">:</span>
                <span class="n">hess</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;hess&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Defaults to BFGS, if not in opt_settings</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">BFGS</span>
                <span class="n">hess</span> <span class="o">=</span> <span class="n">BFGS</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hess</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># compute dynamic simul deriv coloring if option is set</span>
        <span class="k">if</span> <span class="n">coloring_mod</span><span class="o">.</span><span class="n">_use_total_sparsity</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coloring_info</span><span class="p">[</span><span class="s1">&#39;coloring&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="n">coloring_mod</span><span class="o">.</span><span class="n">_DYN_COLORING</span><span class="p">:</span>
                <span class="n">coloring_mod</span><span class="o">.</span><span class="n">dynamic_total_coloring</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                    <span class="n">fname</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_total_coloring_fname</span><span class="p">())</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;dynamic_simul_derivs&#39;</span><span class="p">]:</span>
                <span class="n">warn_deprecation</span><span class="p">(</span><span class="s2">&quot;The &#39;dynamic_simul_derivs&#39; option has been deprecated. Call &quot;</span>
                                 <span class="s2">&quot;the &#39;declare_coloring&#39; function instead.&quot;</span><span class="p">)</span>
                <span class="n">coloring_mod</span><span class="o">.</span><span class="n">dynamic_total_coloring</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                    <span class="n">fname</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_total_coloring_fname</span><span class="p">())</span>

        <span class="c1"># optimize</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">_optimizers</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_objfunc</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span>
                                  <span class="c1"># args=(),</span>
                                  <span class="n">method</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span>
                                  <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span>
                                  <span class="n">hess</span><span class="o">=</span><span class="n">hess</span><span class="p">,</span>
                                  <span class="c1"># hessp=None,</span>
                                  <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                                  <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                                  <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;tol&#39;</span><span class="p">],</span>
                                  <span class="c1"># callback=None,</span>
                                  <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">opt</span> <span class="o">==</span> <span class="s1">&#39;basinhopping&#39;</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">basinhopping</span>

                <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objfunc</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jac</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

                <span class="k">if</span> <span class="s1">&#39;minimizer_kwargs&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">[</span><span class="s1">&#39;minimizer_kwargs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;L-BFGS-B&quot;</span><span class="p">,</span> <span class="s2">&quot;jac&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;maxiter&#39;</span><span class="p">)</span>  <span class="c1"># It does not have this argument</span>

                <span class="k">def</span> <span class="nf">accept_test</span><span class="p">(</span><span class="n">f_new</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">f_old</span><span class="p">,</span> <span class="n">x_old</span><span class="p">):</span>
                    <span class="c1"># Used to implement bounds besides the original functionality</span>
                    <span class="k">if</span> <span class="n">bounds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">bound_check</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">xi</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">xi</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_new</span><span class="p">,</span> <span class="n">bounds</span><span class="p">)])</span>
                        <span class="n">user_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;accept_test&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># callable</span>
                        <span class="c1"># has to satisfy both the bounds and the acceptance test defined by the</span>
                        <span class="c1"># user</span>
                        <span class="k">if</span> <span class="n">user_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">test_res</span> <span class="o">=</span> <span class="n">user_test</span><span class="p">(</span><span class="n">f_new</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">f_old</span><span class="p">,</span> <span class="n">x_old</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">test_res</span> <span class="o">==</span> <span class="s1">&#39;force accept&#39;</span><span class="p">:</span>
                                <span class="k">return</span> <span class="n">test_res</span>
                            <span class="k">else</span><span class="p">:</span>  <span class="c1"># result is boolean</span>
                                <span class="k">return</span> <span class="n">bound_check</span> <span class="ow">and</span> <span class="n">test_res</span>
                        <span class="k">else</span><span class="p">:</span>  <span class="c1"># no user acceptance test, check only the bounds</span>
                            <span class="k">return</span> <span class="n">bound_check</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="kc">True</span>

                <span class="n">result</span> <span class="o">=</span> <span class="n">basinhopping</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span>
                                      <span class="n">accept_test</span><span class="o">=</span><span class="n">accept_test</span><span class="p">,</span>
                                      <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">opt</span> <span class="o">==</span> <span class="s1">&#39;dual_annealing&#39;</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">dual_annealing</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;disp&#39;</span><span class="p">)</span>  <span class="c1"># It does not have this argument</span>
                <span class="c1"># There is no &quot;options&quot; param, so &quot;opt_settings&quot; can be used to set the (many)</span>
                <span class="c1"># keyword arguments</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">dual_annealing</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_objfunc</span><span class="p">,</span>
                                        <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                                        <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">opt</span> <span class="o">==</span> <span class="s1">&#39;differential_evolution&#39;</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">differential_evolution</span>
                <span class="c1"># There is no &quot;options&quot; param, so &quot;opt_settings&quot; can be used to set the (many)</span>
                <span class="c1"># keyword arguments</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">differential_evolution</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_objfunc</span><span class="p">,</span>
                                                <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                                                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">opt</span> <span class="o">==</span> <span class="s1">&#39;shgo&#39;</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">shgo</span>
                <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;minimizer_kwargs&#39;</span><span class="p">,</span> <span class="s1">&#39;sampling_method &#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;iters&#39;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">:</span>
                        <span class="n">kwargs</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">[</span><span class="n">param</span><span class="p">]</span>
                <span class="c1"># Set the Jacobian and the Hessian to the value calculated in OpenMDAO</span>
                <span class="k">if</span> <span class="s1">&#39;minimizer_kwargs&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;minimizer_kwargs&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;minimizer_kwargs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;minimizer_kwargs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;jac&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="p">)</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;minimizer_kwargs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;hess&#39;</span><span class="p">,</span> <span class="n">hess</span><span class="p">)</span>
                <span class="c1"># Objective function tolerance</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">[</span><span class="s1">&#39;f_tol&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;tol&#39;</span><span class="p">]</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">shgo</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_objfunc</span><span class="p">,</span>
                              <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                              <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                              <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_settings</span><span class="p">,</span>
                              <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;Optimizer &quot;</span><span class="si">{}</span><span class="s1">&quot; is not implemented yet. Choose from: </span><span class="si">{}</span><span class="s1">&#39;</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">_all_optimizers</span><span class="p">))</span>

        <span class="c1"># If an exception was swallowed in one of our callbacks, we want to raise it</span>
        <span class="c1"># rather than the cryptic message from scipy.</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">msg</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_reraise</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reraise</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="n">result</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="s1">&#39;success&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fail</span> <span class="o">=</span> <span class="kc">False</span> <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">success</span> <span class="k">else</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fail</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimization FAILED.&#39;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">35</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimization Complete&#39;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">35</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fail</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># It is not known, so the worst option is assumed</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimization Complete (success not known)&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">35</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fail</span></div>

    <span class="k">def</span> <span class="nf">_objfunc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_new</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate and return the objective function.</span>

<span class="sd">        Model is executed here.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_new : ndarray</span>
<span class="sd">            Array containing parameter values at new design point.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Value of the objective function evaluated at the new design point.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_problem</span><span class="o">.</span><span class="n">model</span>

        <span class="k">try</span><span class="p">:</span>

            <span class="c1"># Pass in new parameters</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">iteritems</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_designvars</span><span class="p">):</span>
                <span class="n">size</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;size&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_design_var</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">x_new</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">size</span><span class="p">])</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="n">size</span>

            <span class="k">with</span> <span class="n">RecordingDebugging</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_name</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_count</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span> <span class="k">as</span> <span class="n">rec</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">model</span><span class="o">.</span><span class="n">run_solve_nonlinear</span><span class="p">()</span>

            <span class="c1"># Get the objective function evaluations</span>
            <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">itervalues</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_objective_values</span><span class="p">()):</span>
                <span class="n">f_new</span> <span class="o">=</span> <span class="n">obj</span>
                <span class="k">break</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_con_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_constraint_values</span><span class="p">()</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">msg</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="c1"># print(&quot;Functions calculated&quot;)</span>
        <span class="c1"># print(x_new)</span>
        <span class="c1"># print(f_new)</span>

        <span class="k">return</span> <span class="n">f_new</span>

    <span class="k">def</span> <span class="nf">_con_val_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">dbl</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the value of the constraint function requested in args.</span>

<span class="sd">        The lower or upper bound is **not** subtracted from the value. Used for optimizers,</span>
<span class="sd">        which take the bounds of the constraints (e.g. trust-constr)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_new : ndarray</span>
<span class="sd">            Array containing parameter values at new design point.</span>
<span class="sd">        name : string</span>
<span class="sd">            Name of the constraint to be evaluated.</span>
<span class="sd">        dbl : bool</span>
<span class="sd">            True if double sided constraint.</span>
<span class="sd">        idx : float</span>
<span class="sd">            Contains index into the constraint array.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Value of the constraint function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_con_cache</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_confunc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">dbl</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the value of the constraint function requested in args.</span>

<span class="sd">        Note that this function is called for each constraint, so the model is only run when the</span>
<span class="sd">        objective is evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_new : ndarray</span>
<span class="sd">            Array containing parameter values at new design point.</span>
<span class="sd">        name : string</span>
<span class="sd">            Name of the constraint to be evaluated.</span>
<span class="sd">        dbl : bool</span>
<span class="sd">            True if double sided constraint.</span>
<span class="sd">        idx : float</span>
<span class="sd">            Contains index into the constraint array.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Value of the constraint function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reraise</span><span class="p">()</span>

        <span class="n">cons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_con_cache</span>
        <span class="n">meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cons</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="c1"># Equality constraints</span>
        <span class="n">equals</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;equals&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">equals</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">equals</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">equals</span> <span class="o">=</span> <span class="n">equals</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">cons</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">equals</span>

        <span class="c1"># Note, scipy defines constraints to be satisfied when positive,</span>
        <span class="c1"># which is the opposite of OpenMDAO.</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;upper&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="n">upper</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="n">lower</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="n">lower</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">dbl</span> <span class="ow">or</span> <span class="p">(</span><span class="n">lower</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">openmdao</span><span class="o">.</span><span class="n">INF_BOUND</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">upper</span> <span class="o">-</span> <span class="n">cons</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">cons</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">lower</span>

    <span class="k">def</span> <span class="nf">_gradfunc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_new</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate and return the gradient for the objective.</span>

<span class="sd">        Gradients for the constraints are also calculated and cached here.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_new : ndarray</span>
<span class="sd">            Array containing parameter values at new design point.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ndarray</span>
<span class="sd">            Gradient of objective with respect to parameter array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_totals</span><span class="p">(</span><span class="n">of</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_obj_and_nlcons</span><span class="p">,</span> <span class="n">wrt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dvlist</span><span class="p">,</span>
                                        <span class="n">return_format</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_grad_cache</span> <span class="o">=</span> <span class="n">grad</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">msg</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[]])</span>

        <span class="c1"># print(&quot;Gradients calculated&quot;)</span>
        <span class="c1"># print(x_new)</span>
        <span class="c1"># print(grad[0, :])</span>

        <span class="k">return</span> <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">_congradfunc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">dbl</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the cached gradient of the constraint function.</span>

<span class="sd">        Note, scipy calls the constraints one at a time, so the gradient is cached when the</span>
<span class="sd">        objective gradient is called.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_new : ndarray</span>
<span class="sd">            Array containing parameter values at new design point.</span>
<span class="sd">        name : string</span>
<span class="sd">            Name of the constraint to be evaluated.</span>
<span class="sd">        dbl : bool</span>
<span class="sd">            Denotes if a constraint is double-sided or not.</span>
<span class="sd">        idx : float</span>
<span class="sd">            Contains index into the constraint array.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Gradient of the constraint function wrt all params.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reraise</span><span class="p">()</span>

        <span class="n">meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cons</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lincongrad_cache</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_grad_cache</span>
        <span class="n">grad_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_con_idx</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+</span> <span class="n">idx</span>

        <span class="c1"># print(&quot;Constraint Gradient returned&quot;)</span>
        <span class="c1"># print(x_new)</span>
        <span class="c1"># print(name, idx, grad[grad_idx, :])</span>

        <span class="c1"># Equality constraints</span>
        <span class="k">if</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;equals&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grad</span><span class="p">[</span><span class="n">grad_idx</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># Note, scipy defines constraints to be satisfied when positive,</span>
        <span class="c1"># which is the opposite of OpenMDAO.</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;lower&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="n">lower</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">dbl</span> <span class="ow">or</span> <span class="p">(</span><span class="n">lower</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">openmdao</span><span class="o">.</span><span class="n">INF_BOUND</span><span class="p">):</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">grad</span><span class="p">[</span><span class="n">grad_idx</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grad</span><span class="p">[</span><span class="n">grad_idx</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">_reraise</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reraise any exception encountered when scipy calls back into our method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">exc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_exc_info</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">reraise</span><span class="p">(</span><span class="o">*</span><span class="n">exc</span><span class="p">)</span></div>


<div class="viewcode-block" id="signature_extender"><a class="viewcode-back" href="../../../_srcdocs/packages/drivers/scipy_optimizer.html#openmdao.drivers.scipy_optimizer.signature_extender">[docs]</a><span class="k">def</span> <span class="nf">signature_extender</span><span class="p">(</span><span class="n">fcn</span><span class="p">,</span> <span class="n">extra_args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Closure function, which appends extra arguments to the original function call.</span>

<span class="sd">    The first argument is the design vector. The possible extra arguments from the callback</span>
<span class="sd">    of :func:`scipy.optimize.minimize` are not passed to the function.</span>

<span class="sd">    Some algorithms take a sequence of :class:`~scipy.optimize.NonlinearConstraint` as input</span>
<span class="sd">    for the constraints. For this class it is not possible to pass additional arguments.</span>
<span class="sd">    With this function the signature will be correct for both scipy and the driver.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fcn : callable</span>
<span class="sd">        Function, which takes the design vector as the first argument.</span>
<span class="sd">    extra_args : tuple or list</span>
<span class="sd">        Extra arguments for the function</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    callable</span>
<span class="sd">        The function with the signature expected by the driver.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">closure</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fcn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">extra_args</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">closure</span></div>


<div class="viewcode-block" id="ScipyOptimizer"><a class="viewcode-back" href="../../../_srcdocs/packages/drivers/scipy_optimizer.html#openmdao.drivers.scipy_optimizer.ScipyOptimizer">[docs]</a><span class="k">class</span> <span class="nc">ScipyOptimizer</span><span class="p">(</span><span class="n">ScipyOptimizeDriver</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deprecated.  Use ScipyOptimizeDriver.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ScipyOptimizer.__init__"><a class="viewcode-back" href="../../../_srcdocs/packages/drivers/scipy_optimizer.html#openmdao.drivers.scipy_optimizer.ScipyOptimizer.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize attributes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        **kwargs : dict</span>
<span class="sd">            Named args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ScipyOptimizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">warn_deprecation</span><span class="p">(</span><span class="s2">&quot;&#39;ScipyOptimizer&#39; provides backwards compatibility &quot;</span>
                         <span class="s2">&quot;with OpenMDAO &lt;= 2.2 ; use &#39;ScipyOptimizeDriver&#39; instead.&quot;</span><span class="p">)</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">OpenMDAO 2.8.0 Beta documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, openmdao.org.
      Last updated on Aug 08, 2019.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.1.
    </div>
  </body>
</html>