
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>openmdao.surrogate_models.multifi_cokriging &#8212; OpenMDAO 2.8.0 Beta documentation</title>
    <link rel="stylesheet" href="../../../_static/style.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/OpenMDAO_Favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">OpenMDAO 2.8.0 Beta documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/OpenMDAO_Logo.png" alt="Logo"/>
            </a></p>
<h3><a href="../../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/index.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../basic_guide/index.html">Basic User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced_guide/index.html">Advanced User Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../features/index.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../theory_manual/index.html">Theory Manual</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../other/om_command.html">Command Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/citing.html">How to Cite OpenMDAO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/repo_guide/index.html">Building a Tool on Top of OpenMDAO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/api_translation.html">Upgrading from OpenMDAO 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../other/file_wrap.html">File Wrapping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../_srcdocs/index.html">Source Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer_docs/index.html">Developer Docs (if youâ€™re going to contribute code)</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Search OpenMDAO</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="checkbox" name="search_source" /> Include Source Docs
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for openmdao.surrogate_models.multifi_cokriging</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Integrates the Multi-Fidelity Co-Kriging method described in [LeGratiet2013].</span>

<span class="sd">(Author: Remi Vauclin vauclin.remi@gmail.com)</span>

<span class="sd">This code was implemented using the package scikit-learn as basis.</span>
<span class="sd">(Author: Vincent Dubourg, vincent.dubourg@gmail.com)</span>

<span class="sd">OpenMDAO adaptation. Regression and correlation functions were directly copied</span>
<span class="sd">from scikit-learn package here to avoid scikit-learn dependency.</span>
<span class="sd">(Author: Remi Lafage, remi.lafage@onera.fr)</span>

<span class="sd">ISAE/DMSM - ONERA/DCPS</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="n">atleast_2d</span> <span class="k">as</span> <span class="n">array2d</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">linalg</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="k">import</span> <span class="n">squareform</span>

<span class="kn">from</span> <span class="nn">openmdao.surrogate_models.surrogate_model</span> <span class="k">import</span> <span class="n">MultiFiSurrogateModel</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>

<span class="n">MACHINE_EPSILON</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>  <span class="c1"># machine precision</span>
<span class="n">NUGGET</span> <span class="o">=</span> <span class="mf">10.</span> <span class="o">*</span> <span class="n">MACHINE_EPSILON</span>  <span class="c1"># nugget for robustness</span>

<span class="n">INITIAL_RANGE_DEFAULT</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># initial range for optimizer</span>
<span class="n">TOLERANCE_DEFAULT</span> <span class="o">=</span> <span class="mf">1e-6</span>    <span class="c1"># stopping criterion for MLE optimization</span>

<span class="n">THETA0_DEFAULT</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">THETAL_DEFAULT</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">THETAU_DEFAULT</span> <span class="o">=</span> <span class="mi">50</span>

<span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">linalg</span><span class="p">,</span> <span class="s1">&#39;solve_triangular&#39;</span><span class="p">):</span>
    <span class="c1"># only in scipy since 0.9</span>
    <span class="n">solve_triangular</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># slower, but works</span>
    <span class="k">def</span> <span class="nf">solve_triangular</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Solve triangular.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


<div class="viewcode-block" id="constant_regression"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.constant_regression">[docs]</a><span class="k">def</span> <span class="nf">constant_regression</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Zero order polynomial (constant, p = 1) regression model.</span>

<span class="sd">    x --&gt; f(x) = 1</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        Input data.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    array_like</span>
<span class="sd">        Constant regression output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">n_eval</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_eval</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">f</span></div>


<div class="viewcode-block" id="linear_regression"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.linear_regression">[docs]</a><span class="k">def</span> <span class="nf">linear_regression</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    First order polynomial (linear, p = n+1) regression model.</span>

<span class="sd">    x --&gt; f(x) = [ 1, x_1, ..., x_n ].T</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        Input data.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    array_like</span>
<span class="sd">        Linear regression output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">n_eval</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_eval</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">x</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">f</span></div>


<div class="viewcode-block" id="squared_exponential_correlation"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.squared_exponential_correlation">[docs]</a><span class="k">def</span> <span class="nf">squared_exponential_correlation</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Squared exponential correlation model (Radial Basis Function).</span>

<span class="sd">    (Infinitely differentiable stochastic process, very smooth)::</span>

<span class="sd">                                            n</span>
<span class="sd">        theta, dx --&gt; r(theta, dx) = exp(  sum  - theta_i * (dx_i)^2 )</span>
<span class="sd">                                          i = 1</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    theta : array_like</span>
<span class="sd">        An array with shape 1 (isotropic) or n (anisotropic) giving the</span>
<span class="sd">        autocorrelation parameter(s).</span>
<span class="sd">    d : array_like</span>
<span class="sd">        An array with shape (n_eval, n_features) giving the componentwise</span>
<span class="sd">        distances between locations x and x&#39; at which the correlation model</span>
<span class="sd">        should be evaluated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    r : array_like</span>
<span class="sd">        An array with shape (n_eval, ) containing the values of the</span>
<span class="sd">        autocorrelation model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">theta</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">theta</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">n_features</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Length of theta must be 1 or </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span></div>


<div class="viewcode-block" id="l1_cross_distances"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.l1_cross_distances">[docs]</a><span class="k">def</span> <span class="nf">l1_cross_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the nonzero componentwise L1 cross-distances between the vectors in X and Y.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array_like</span>
<span class="sd">        An array with shape (n_samples_X, n_features)</span>
<span class="sd">    Y : array_like</span>
<span class="sd">        An array with shape (n_samples_Y, n_features)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    array with shape (n_samples * (n_samples - 1) / 2, n_features)</span>
<span class="sd">        The array of componentwise L1 cross-distances.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">n_nonzero_cross_dist</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nonzero_cross_dist</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
        <span class="n">ll_1</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">ll_0</span> <span class="o">=</span> <span class="n">ll_1</span>
            <span class="n">ll_1</span> <span class="o">=</span> <span class="n">ll_0</span> <span class="o">+</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">k</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">D</span><span class="p">[</span><span class="n">ll_0</span><span class="p">:</span><span class="n">ll_1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="n">n_samples_X</span><span class="p">,</span> <span class="n">n_features_X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">n_samples_Y</span><span class="p">,</span> <span class="n">n_features_Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">n_features_X</span> <span class="o">!=</span> <span class="n">n_features_Y</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and Y must have the same dimensions.&quot;</span><span class="p">)</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features_X</span>

        <span class="n">n_nonzero_cross_dist</span> <span class="o">=</span> <span class="n">n_samples_X</span> <span class="o">*</span> <span class="n">n_samples_Y</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nonzero_cross_dist</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
        <span class="n">ll_1</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples_X</span><span class="p">):</span>
            <span class="n">ll_0</span> <span class="o">=</span> <span class="n">ll_1</span>
            <span class="n">ll_1</span> <span class="o">=</span> <span class="n">ll_0</span> <span class="o">+</span> <span class="n">n_samples_Y</span>  <span class="c1"># - k - 1</span>
            <span class="n">D</span><span class="p">[</span><span class="n">ll_0</span><span class="p">:</span><span class="n">ll_1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">D</span></div>


<div class="viewcode-block" id="MultiFiCoKriging"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKriging">[docs]</a><span class="k">class</span> <span class="nc">MultiFiCoKriging</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Integrate the Multi-Fidelity Co-Kriging method described in [LeGratiet2013].</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    corr : Object</span>
<span class="sd">        Correlation function to use, default is squared_exponential_correlation.</span>
<span class="sd">    normalize : bool, optional</span>
<span class="sd">        When true, normalize X and Y so that the mean is at zero.</span>
<span class="sd">    regr : string or callable</span>
<span class="sd">        A regression function returning an array of outputs of the linear</span>
<span class="sd">        regression functional basis for Universal Kriging purpose.</span>
<span class="sd">        regr is assumed to be the same for all levels of code.</span>
<span class="sd">        Default assumes a simple constant regression trend.</span>
<span class="sd">        Available built-in regression models are:</span>
<span class="sd">        &#39;constant&#39;, &#39;linear&#39;</span>
<span class="sd">    rho_regr : string or callable or None</span>
<span class="sd">        A regression function returning an array of outputs of the linear</span>
<span class="sd">        regression functional basis. Defines the regression function for the</span>
<span class="sd">        autoregressive parameter rho.</span>
<span class="sd">        rho_regr is assumed to be the same for all levels of code.</span>
<span class="sd">        Default assumes a simple constant regression trend.</span>
<span class="sd">        Available built-in regression models are:</span>
<span class="sd">        &#39;constant&#39;, &#39;linear&#39;</span>
<span class="sd">    theta : double, array_like or list or None</span>
<span class="sd">        Value of correlation parameters if they are known; no optimization is run.</span>
<span class="sd">        Default is None, so that optimization is run.</span>
<span class="sd">        if double: value is replicated for all features and all levels.</span>
<span class="sd">        if array_like: an array with shape (n_features, ) for</span>
<span class="sd">        isotropic calculation. It is replicated for all levels.</span>
<span class="sd">        if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">    theta0 : double, array_like or list or None</span>
<span class="sd">        Starting point for the maximum likelihood estimation of the</span>
<span class="sd">        best set of parameters.</span>
<span class="sd">        Default is None and meaning use of the default 0.5*np.ones(n_features)</span>
<span class="sd">        if double: value is replicated for all features and all levels.</span>
<span class="sd">        if array_like: an array with shape (n_features, ) for</span>
<span class="sd">        isotropic calculation. It is replicated for all levels.</span>
<span class="sd">        if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">    thetaL : double, array_like or list or None</span>
<span class="sd">        Lower bound on the autocorrelation parameters for maximum</span>
<span class="sd">        likelihood estimation.</span>
<span class="sd">        Default is None meaning use of the default 1e-5*np.ones(n_features).</span>
<span class="sd">        if double: value is replicated for all features and all levels.</span>
<span class="sd">        if array_like: An array with shape matching theta0&#39;s. It is replicated</span>
<span class="sd">        for all levels of code.</span>
<span class="sd">        if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">    thetaU : double, array_like or list or None</span>
<span class="sd">        Upper bound on the autocorrelation parameters for maximum</span>
<span class="sd">        likelihood estimation.</span>
<span class="sd">        Default is None meaning use of default value 50*np.ones(n_features).</span>
<span class="sd">        if double: value is replicated for all features and all levels.</span>
<span class="sd">        if array_like: An array with shape matching theta0&#39;s. It is replicated</span>
<span class="sd">        for all levels of code.</span>
<span class="sd">        if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">    X_mean : float</span>
<span class="sd">        Mean of the low fidelity training data for X.</span>
<span class="sd">    X_std : float</span>
<span class="sd">        Standard deviation of the low fidelity training data for X.</span>
<span class="sd">    y_mean : float</span>
<span class="sd">        Mean of the low fidelity training data for y.</span>
<span class="sd">    y_std : float</span>
<span class="sd">        Standard deviation of the low fidelity training data for y.</span>
<span class="sd">    _nfev : int</span>
<span class="sd">        Number of function evaluations.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from openmdao.surrogate_models.multifi_cokriging import MultiFiCoKriging</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; # Xe: DOE for expensive code (nested in Xc)</span>
<span class="sd">    &gt;&gt;&gt; # Xc: DOE for cheap code</span>
<span class="sd">    &gt;&gt;&gt; # ye: expensive response</span>
<span class="sd">    &gt;&gt;&gt; # yc: cheap response</span>
<span class="sd">    &gt;&gt;&gt; Xe = np.array([[0],[0.4],[1]])</span>
<span class="sd">    &gt;&gt;&gt; Xc = np.vstack((np.array([[0.1],[0.2],[0.3],[0.5],[0.6],[0.7],[0.8],[0.9]]),Xe))</span>
<span class="sd">    &gt;&gt;&gt; ye = ((Xe*6-2)**2)*np.sin((Xe*6-2)*2)</span>
<span class="sd">    &gt;&gt;&gt; yc = 0.5*((Xc*6-2)**2)*np.sin((Xc*6-2)*2)+(Xc-0.5)*10. - 5</span>
<span class="sd">    &gt;&gt;&gt; model = MultiFiCoKriging(theta0=1, thetaL=1e-5, thetaU=50.)</span>
<span class="sd">    &gt;&gt;&gt; model.fit([Xc, Xe], [yc, ye])</span>
<span class="sd">    &gt;&gt;&gt; # Prediction on x=0.05</span>
<span class="sd">    &gt;&gt;&gt; np.abs(float(model.predict([0.05])[0])- ((0.05*6-2)**2)*np.sin((0.05*6-2)*2)) &lt; 0.05</span>
<span class="sd">    True</span>


<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Implementation is based on the Package Scikit-Learn</span>
<span class="sd">    (Author: Vincent Dubourg, vincent.dubourg@gmail.com) which translates</span>
<span class="sd">    the DACE Matlab toolbox, see [NLNS2002]_.</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [NLNS2002] H. B. Nielsen, S. N. Lophaven, and J. Sondergaard.</span>
<span class="sd">       `DACE - A MATLAB Kriging Toolbox.` (2002)</span>
<span class="sd">       http://www2.imm.dtu.dk/~hbn/dace/dace.pdf</span>

<span class="sd">    .. [WBSWM1992] W. J. Welch, R. J. Buck, J. Sacks, H. P. Wynn, T. J. Mitchell,</span>
<span class="sd">       and M. D. Morris (1992). &quot;Screening, predicting, and computer experiments.&quot;</span>
<span class="sd">       `Technometrics,` 34(1) 15--25.</span>
<span class="sd">       http://www.jstor.org/pss/1269548</span>

<span class="sd">    .. [LeGratiet2013] L. Le Gratiet (2013). &quot;Multi-fidelity Gaussian process</span>
<span class="sd">       regression for computer experiments.&quot;</span>
<span class="sd">       PhD thesis, Universite Paris-Diderot-Paris VII.</span>

<span class="sd">    .. [TBKH2011] Toal, D. J., Bressloff, N. W., Keane, A. J., &amp; Holden, C. M. E. (2011).</span>
<span class="sd">       &quot;The development of a hybridized particle swarm for kriging hyperparameter</span>
<span class="sd">       tuning.&quot; `Engineering optimization`, 43(6), 675-699.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_regression_types</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;constant&#39;</span><span class="p">:</span> <span class="n">constant_regression</span><span class="p">,</span>
        <span class="s1">&#39;linear&#39;</span><span class="p">:</span> <span class="n">linear_regression</span>
    <span class="p">}</span>

<div class="viewcode-block" id="MultiFiCoKriging.__init__"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKriging.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regr</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">rho_regr</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">theta0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">thetaL</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">thetaU</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize all attributes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        regr : string or callable, optional</span>
<span class="sd">            A regression function returning an array of outputs of the linear</span>
<span class="sd">            regression functional basis for Universal Kriging purpose.</span>
<span class="sd">            regr is assumed to be the same for all levels of code.</span>
<span class="sd">            Default assumes a simple constant regression trend.</span>
<span class="sd">            Available built-in regression models are:</span>
<span class="sd">            &#39;constant&#39;, &#39;linear&#39;</span>
<span class="sd">        rho_regr : string or callable, optional</span>
<span class="sd">            A regression function returning an array of outputs of the linear</span>
<span class="sd">            regression functional basis. Defines the regression function for the</span>
<span class="sd">            autoregressive parameter rho.</span>
<span class="sd">            rho_regr is assumed to be the same for all levels of code.</span>
<span class="sd">            Default assumes a simple constant regression trend.</span>
<span class="sd">            Available built-in regression models are:</span>
<span class="sd">            &#39;constant&#39;, &#39;linear&#39;</span>
<span class="sd">        theta : double, array_like or list, optional</span>
<span class="sd">            Value of correlation parameters if they are known; no optimization is run.</span>
<span class="sd">            Default is None, so that optimization is run.</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: an array with shape (n_features, ) for</span>
<span class="sd">            isotropic calculation. It is replicated for all levels.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        theta0 : double, array_like or list, optional</span>
<span class="sd">            Starting point for the maximum likelihood estimation of the</span>
<span class="sd">            best set of parameters.</span>
<span class="sd">            Default is None and meaning use of the default 0.5*np.ones(n_features)</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: an array with shape (n_features, ) for</span>
<span class="sd">            isotropic calculation. It is replicated for all levels.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        thetaL : double, array_like or list, optional</span>
<span class="sd">            Lower bound on the autocorrelation parameters for maximum</span>
<span class="sd">            likelihood estimation.</span>
<span class="sd">            Default is None meaning use of the default 1e-5*np.ones(n_features).</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: An array with shape matching theta0&#39;s. It is replicated</span>
<span class="sd">            for all levels of code.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        thetaU : double, array_like or list, optional</span>
<span class="sd">            Upper bound on the autocorrelation parameters for maximum</span>
<span class="sd">            likelihood estimation.</span>
<span class="sd">            Default is None meaning use of default value 50*np.ones(n_features).</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: An array with shape matching theta0&#39;s. It is replicated</span>
<span class="sd">            for all levels of code.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        normalize : bool, optional</span>
<span class="sd">            When true, normalize X and Y so that the mean is at zero.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corr</span> <span class="o">=</span> <span class="n">squared_exponential_correlation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="n">regr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span> <span class="o">=</span> <span class="n">rho_regr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span> <span class="o">=</span> <span class="n">theta0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">thetaL</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">thetaU</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">=</span> <span class="mi">0</span></div>

    <span class="k">def</span> <span class="nf">_build_R</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the correlation matrix with given theta for the specified level.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lvl : Integer</span>
<span class="sd">            Level of fidelity</span>
<span class="sd">        theta : array_like</span>
<span class="sd">            An array containing the autocorrelation parameters at which the</span>
<span class="sd">            Gaussian Process model parameters should be determined.</span>
<span class="sd">            Default uses the built-in autocorrelation parameters</span>
<span class="sd">            (ie ``theta = self.theta``).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ndarray</span>
<span class="sd">            Correlatioin matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>

        <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">NUGGET</span><span class="p">)</span>

        <span class="n">corr</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">D</span><span class="p">))</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">R</span> <span class="o">+</span> <span class="n">corr</span>

        <span class="k">return</span> <span class="n">R</span>

<div class="viewcode-block" id="MultiFiCoKriging.fit"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKriging.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">initial_range</span><span class="o">=</span><span class="n">INITIAL_RANGE_DEFAULT</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOLERANCE_DEFAULT</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the Multi-Fidelity co-kriging model fitting method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : list of double array_like elements</span>
<span class="sd">            A list of arrays with the input at which observations were made, from lowest</span>
<span class="sd">            fidelity to highest fidelity. Designs must be nested</span>
<span class="sd">            with X[i] = np.vstack([..., X[i+1])</span>
<span class="sd">        y : list of double array_like elements</span>
<span class="sd">            A list of arrays with the observations of the scalar output to be predicted,</span>
<span class="sd">            from lowest fidelity to highest fidelity.</span>
<span class="sd">        initial_range : float</span>
<span class="sd">            Initial range for the optimizer.</span>
<span class="sd">        tol : float</span>
<span class="sd">            Optimizer terminates when the tolerance tol is reached.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Run input checks</span>
        <span class="c1"># Transforms floats and arrays in lists to have a multifidelity</span>
        <span class="c1"># structure</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_list_structure</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># Checks if all parameters are structured as required</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
        <span class="n">nlevel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nlevel</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span>

        <span class="c1"># initialize lists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_rho</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_regr</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_R_adj</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>

        <span class="c1"># Training data will be normalized using statistical quantities from the low fidelity set.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span> <span class="o">=</span> <span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span> <span class="o">=</span> <span class="n">X_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">=</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">X_std</span><span class="p">[</span><span class="n">X_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
            <span class="n">y_std</span><span class="p">[</span><span class="n">y_std</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

        <span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlevel</span><span class="p">):</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
                <span class="n">X</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_std</span>
                <span class="n">y</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

            <span class="c1"># Calculate matrix of distances D between samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">lvl</span><span class="p">])</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">[</span><span class="n">lvl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Multiple input features cannot have the same&quot;</span>
                                <span class="s2">&quot; value.&quot;</span><span class="p">)</span>

            <span class="c1"># Regression matrix and parameters</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">lvl</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Concatenate the autoregressive part for levels &gt; 0</span>
            <span class="k">if</span> <span class="n">lvl</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">F_rho</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">lvl</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">F_rho</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">F_rho</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">lvl</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])[</span><span class="o">-</span><span class="n">n_samples</span><span class="p">[</span><span class="n">lvl</span><span class="p">]:],</span>
                                                        <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">lvl</span><span class="p">]))),</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">lvl</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">n_samples_F_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">n_samples_F_i</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">[</span><span class="n">lvl</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Number of rows in F and X do not match. Most &quot;</span>
                                <span class="s2">&quot;likely something is going wrong with the &quot;</span>
                                <span class="s2">&quot;regression model.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">lvl</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="n">n_samples_F_i</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="s2">&quot;Ordinary least squares problem is undetermined &quot;</span>
                                 <span class="s2">&quot;n_samples=</span><span class="si">%d</span><span class="s2"> must be greater than the regression&quot;</span>
                                 <span class="s2">&quot; model size p+q=</span><span class="si">%d</span><span class="s2">.&quot;</span><span class="p">)</span>
                                <span class="o">%</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">lvl</span><span class="p">]))</span>

        <span class="c1"># Set attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rlf_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nlevel</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">lvl</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlevel</span><span class="p">):</span>
            <span class="c1"># Determine Gaussian Process model parameters</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Maximum Likelihood Estimation of the parameters</span>
                <span class="n">sol</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_rlf</span><span class="p">(</span>
                    <span class="n">lvl</span><span class="o">=</span><span class="n">lvl</span><span class="p">,</span> <span class="n">initial_range</span><span class="o">=</span><span class="n">initial_range</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rlf_value</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;rlf_value&#39;</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rlf_value</span><span class="p">[</span><span class="n">lvl</span><span class="p">]):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Bad parameter region. &quot;</span>
                                    <span class="s2">&quot;Try increasing upper bound&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rlf_value</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rlf</span><span class="p">(</span><span class="n">lvl</span><span class="o">=</span><span class="n">lvl</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rlf_value</span><span class="p">[</span><span class="n">lvl</span><span class="p">]):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Bad point. Try increasing theta0.&quot;</span><span class="p">)</span>

        <span class="k">return</span></div>

<div class="viewcode-block" id="MultiFiCoKriging.rlf"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKriging.rlf">[docs]</a>    <span class="k">def</span> <span class="nf">rlf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine BLUP parameters and evaluate negative reduced likelihood function for theta.</span>

<span class="sd">        Maximizing this function wrt the autocorrelation parameters theta is</span>
<span class="sd">        equivalent to maximizing the likelihood of the assumed joint Gaussian</span>
<span class="sd">        distribution of the observations y evaluated onto the design of</span>
<span class="sd">        experiments X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lvl : Integer</span>
<span class="sd">            Level of fidelity</span>
<span class="sd">        theta : array_like, optional</span>
<span class="sd">            An array containing the autocorrelation parameters at which the</span>
<span class="sd">            Gaussian Process model parameters should be determined.</span>
<span class="sd">            Default uses the built-in autocorrelation parameters</span>
<span class="sd">            (ie ``theta = self.theta``).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        double</span>
<span class="sd">            The value of the negative concentrated reduced likelihood function</span>
<span class="sd">            associated to the given autocorrelation parameters theta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use built-in autocorrelation parameters</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>

        <span class="c1"># Initialize output</span>
        <span class="n">rlf_value</span> <span class="o">=</span> <span class="mf">1e20</span>

        <span class="c1"># Retrieve data</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>

        <span class="n">R</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_R</span><span class="p">(</span><span class="n">lvl</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">((</span><span class="s1">&#39;Cholesky decomposition of R at level </span><span class="si">%i</span><span class="s1"> failed&#39;</span> <span class="o">%</span> <span class="n">lvl</span><span class="p">)</span> <span class="o">+</span>
                            <span class="s1">&#39; with theta=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">rlf_value</span>

        <span class="c1"># Get generalized least squares solution</span>
        <span class="n">Ft</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">Yt</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>   <span class="c1"># qr() got an unexpected keyword argument &#39;econ&#39;</span>
            <span class="c1"># DeprecationWarning: qr econ argument will be removed after scipy</span>
            <span class="c1"># 0.7. The economy transform will then be available through the</span>
            <span class="c1"># mode=&#39;economic&#39; argument.</span>
            <span class="n">Q</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;economic&#39;</span><span class="p">)</span>
            <span class="k">pass</span>

        <span class="c1"># Universal Kriging</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Yt</span><span class="p">))</span>

        <span class="n">err</span> <span class="o">=</span> <span class="n">Yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="n">err2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">err</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">err</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_err</span> <span class="o">=</span> <span class="n">err</span>
        <span class="n">sigma2</span> <span class="o">=</span> <span class="n">err2</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">p</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span>
        <span class="n">detR</span> <span class="o">=</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">))</span><span class="o">**</span><span class="p">(</span><span class="mf">2.</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">))</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>

        <span class="n">rlf_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">p</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">sigma2</span><span class="p">)</span> \
            <span class="o">+</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">detR</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">beta_rho</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[:</span><span class="n">q</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_regr</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span><span class="p">[</span><span class="n">q</span><span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span>

        <span class="k">return</span> <span class="n">rlf_value</span></div>

    <span class="k">def</span> <span class="nf">_max_rlf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="n">initial_range</span><span class="p">,</span> <span class="n">tol</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate autocorrelation parameter theta as maximizer of the reduced likelihood function.</span>

<span class="sd">        (Minimization of the negative reduced likelihood function is used for convenience.)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lvl : integer</span>
<span class="sd">            Level of fidelity</span>
<span class="sd">        initial_range : float</span>
<span class="sd">            Initial range of the optimizer</span>
<span class="sd">        tol : float</span>
<span class="sd">            Optimizer terminates when the tolerance tol is reached.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        array_like</span>
<span class="sd">            The optimal hyperparameters.</span>
<span class="sd">        double</span>
<span class="sd">            The optimal negative reduced likelihood function value.</span>
<span class="sd">        dict</span>
<span class="sd">            res[&#39;theta&#39;]: optimal theta</span>
<span class="sd">            res[&#39;rlf_value&#39;]: optimal value for likelihood</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize input</span>
        <span class="n">thetaL</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">thetaU</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">rlf_transform</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rlf</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">10.</span><span class="o">**</span><span class="n">x</span><span class="p">,</span> <span class="n">lvl</span><span class="o">=</span><span class="n">lvl</span><span class="p">)</span>

        <span class="c1"># Use specified starting point as first guess</span>
        <span class="n">theta0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theta0</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">constraints</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">theta0</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">log10t</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">:</span>
                                <span class="n">log10t</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">thetaL</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])})</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">log10t</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">:</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">thetaU</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="n">log10t</span><span class="p">[</span><span class="n">i</span><span class="p">]})</span>

        <span class="n">constraints</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">constraints</span><span class="p">)</span>
        <span class="n">sol</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">rlf_transform</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;COBYLA&#39;</span><span class="p">,</span>
                       <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
                       <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;rhobeg&#39;</span><span class="p">:</span> <span class="n">initial_range</span><span class="p">,</span>
                                <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="n">tol</span><span class="p">,</span> <span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

        <span class="n">log10_optimal_x</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
        <span class="n">optimal_rlf_value</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">+=</span> <span class="n">sol</span><span class="p">[</span><span class="s1">&#39;nfev&#39;</span><span class="p">]</span>

        <span class="n">optimal_theta</span> <span class="o">=</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">log10_optimal_x</span>

        <span class="n">res</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimal_theta</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;rlf_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimal_rlf_value</span>

        <span class="k">return</span> <span class="n">res</span>

<div class="viewcode-block" id="MultiFiCoKriging.predict"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKriging.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">eval_MSE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform the predictions of the kriging model on X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array_like</span>
<span class="sd">            An array with shape (n_eval, n_features) giving the point(s) at</span>
<span class="sd">            which the prediction(s) should be made.</span>
<span class="sd">        eval_MSE : boolean, optional</span>
<span class="sd">            A boolean specifying whether the Mean Squared Error should be</span>
<span class="sd">            evaluated or not. Default assumes evalMSE is True.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        array_like</span>
<span class="sd">            An array with shape (n_eval, ) with the Best Linear Unbiased</span>
<span class="sd">            Prediction at X. If all_levels is set to True, an array</span>
<span class="sd">            with shape (n_eval, nlevel) giving the BLUP for all levels.</span>
<span class="sd">        array_like, optional (if eval_MSE is True)</span>
<span class="sd">            An array with shape (n_eval, ) with the Mean Squared Error at X.</span>
<span class="sd">            If all_levels is set to True, an array with shape (n_eval, nlevel)</span>
<span class="sd">            giving the MSE for all levels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">nlevel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nlevel</span>
        <span class="n">n_eval</span><span class="p">,</span> <span class="n">n_features_X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Normalize</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_std</span>

        <span class="c1"># Calculate kriging mean and variance at level 0</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">nlevel</span><span class="p">))</span>

        <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">f0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Get regression function and correlation</span>
        <span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Ft</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">yt</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">r_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_eval</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">),</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Scaled predictor</span>
        <span class="n">mu</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r_</span><span class="p">,</span> <span class="n">gamma</span><span class="p">))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sigma2_rho</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
            <span class="n">MSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_eval</span><span class="p">,</span> <span class="n">nlevel</span><span class="p">))</span>
            <span class="n">r_t</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">r_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">u_</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">r_t</span><span class="p">),</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">MSE</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> \
                <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">r_t</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">u_</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Calculate recursively kriging mean and variance at level i</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nlevel</span><span class="p">):</span>
            <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">dx</span> <span class="o">=</span> <span class="n">l1_cross_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">r_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="n">n_eval</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">g</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">mu</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">f0</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

            <span class="n">Ft</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">r_t</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">r_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># scaled predictor</span>
            <span class="n">mu</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
                        <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r_t</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">)))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
                <span class="n">Q_</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                             <span class="n">yt</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="p">,</span> <span class="n">beta</span><span class="p">)))[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="n">u_</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">f</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ft</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">r_t</span><span class="p">),</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">sigma2_rho</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="p">[</span>
                                        <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="p">))[:</span><span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                                    <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">beta</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
                <span class="n">sigma2_rho</span> <span class="o">=</span> <span class="p">(</span><span class="n">sigma2_rho</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="n">MSE</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma2_rho</span> <span class="o">*</span> <span class="n">MSE</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> \
                    <span class="o">+</span> <span class="n">Q_</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> \
                    <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">r_t</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> \
                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># scaled predictor</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlevel</span><span class="p">):</span>  <span class="c1"># Predictor</span>
            <span class="n">mu</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span> <span class="o">*</span> <span class="n">mu</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
                <span class="n">MSE</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_std</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">MSE</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">eval_MSE</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mu</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_eval</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">MSE</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_eval</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mu</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_eval</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="nf">_check_list_structure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform floats and arrays in the training data lists to have a multifidelity structure.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : list of double array_like elements</span>
<span class="sd">            A list of arrays with the input at which observations were made, from lowest</span>
<span class="sd">            fidelity to highest fidelity. Designs must be nested</span>
<span class="sd">            with X[i] = np.vstack([..., X[i+1])</span>
<span class="sd">        y : list of double array_like elements</span>
<span class="sd">            A list of arrays with the observations of the scalar output to be predicted,</span>
<span class="sd">            from lowest fidelity to highest fidelity.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">nlevel</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nlevel</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have the same length.&quot;</span><span class="p">)</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nlevel</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nlevel</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">n_samples_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nlevel</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlevel</span><span class="p">):</span>
            <span class="n">n_samples</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">n_features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n_features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_features</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All X must have the same number of columns.&quot;</span><span class="p">)</span>
            <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">ravel</span><span class="p">()[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="n">n_samples_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">n_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_samples_y</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have the same number of rows.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span> <span class="o">!=</span> <span class="n">nlevel</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta must be a list of </span><span class="si">%d</span><span class="s2"> element(s).&quot;</span> <span class="o">%</span> <span class="n">nlevel</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">)</span> <span class="o">!=</span> <span class="n">nlevel</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta0 must be a list of </span><span class="si">%d</span><span class="s2"> elements.&quot;</span> <span class="o">%</span> <span class="n">nlevel</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">)</span> <span class="o">!=</span> <span class="n">nlevel</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;thetaL must be a list of </span><span class="si">%d</span><span class="s2"> elements.&quot;</span> <span class="o">%</span> <span class="n">nlevel</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span> <span class="o">=</span> <span class="n">nlevel</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">)</span> <span class="o">!=</span> <span class="n">nlevel</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;thetaU must be a list of </span><span class="si">%d</span><span class="s2"> elements.&quot;</span> <span class="o">%</span> <span class="n">nlevel</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nlevel</span> <span class="o">=</span> <span class="n">nlevel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>

        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform sanity checks on all parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check regression model</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">regr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;regr should be one of </span><span class="si">%s</span><span class="s2"> or callable, &quot;</span>
                                 <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> was given.&quot;</span>
                                 <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">regr</span><span class="p">))</span>

        <span class="c1"># Check rho regression model</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;rho_regr should be one of </span><span class="si">%s</span><span class="s2"> or callable, &quot;</span>
                                 <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> was given.&quot;</span>
                                 <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_regression_types</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_regr</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlevel</span><span class="p">):</span>
            <span class="c1"># Check correlation parameters</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta0 must be strictly positive.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta0 must be strictly positive.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">*</span> <span class="p">[</span><span class="n">THETA0_DEFAULT</span><span class="p">])</span>

            <span class="n">lth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">lth</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta0 and thetaL must have the &quot;</span>
                                     <span class="s2">&quot;same length.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">*</span> <span class="p">[</span><span class="n">THETAL_DEFAULT</span><span class="p">])</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">lth</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta0 and thetaU must have the &quot;</span>
                                     <span class="s2">&quot;same length.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">array2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">*</span> <span class="p">[</span><span class="n">THETAU_DEFAULT</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thetaU</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">thetaL</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The bounds must satisfy O &lt; thetaL &lt;= &quot;</span>
                                 <span class="s2">&quot;thetaU.&quot;</span><span class="p">)</span>

        <span class="k">return</span></div>


<div class="viewcode-block" id="MultiFiCoKrigingSurrogate"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKrigingSurrogate">[docs]</a><span class="k">class</span> <span class="nc">MultiFiCoKrigingSurrogate</span><span class="p">(</span><span class="n">MultiFiSurrogateModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    OpenMDAO adapter of multi-fidelity recursive cokriging method described in [LeGratiet2013].</span>

<span class="sd">    See MultiFiCoKriging class.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    initial_range : float</span>
<span class="sd">        Initial range for the optimizer.</span>
<span class="sd">    model : MultiFiCoKriging</span>
<span class="sd">        Contains MultiFiCoKriging surrogate.</span>
<span class="sd">    tolerance : float</span>
<span class="sd">        Optimizer terminates when the tolerance tol is reached.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="MultiFiCoKrigingSurrogate.__init__"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKrigingSurrogate.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regr</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">rho_regr</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">theta0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">thetaL</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">thetaU</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">tolerance</span><span class="o">=</span><span class="n">TOLERANCE_DEFAULT</span><span class="p">,</span> <span class="n">initial_range</span><span class="o">=</span><span class="n">INITIAL_RANGE_DEFAULT</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize all attributes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        normalize : bool, optional</span>
<span class="sd">            When true, normalize X and Y so that the mean is at zero.</span>
<span class="sd">        regr : string or callable, optional</span>
<span class="sd">            A regression function returning an array of outputs of the linear</span>
<span class="sd">            regression functional basis for Universal Kriging purpose.</span>
<span class="sd">            regr is assumed to be the same for all levels of code.</span>
<span class="sd">            Default assumes a simple constant regression trend.</span>
<span class="sd">            Available built-in regression models are:</span>
<span class="sd">            &#39;constant&#39;, &#39;linear&#39;</span>
<span class="sd">        rho_regr : string or callable, optional</span>
<span class="sd">            A regression function returning an array of outputs of the linear</span>
<span class="sd">            regression functional basis. Defines the regression function for the</span>
<span class="sd">            autoregressive parameter rho.</span>
<span class="sd">            rho_regr is assumed to be the same for all levels of code.</span>
<span class="sd">            Default assumes a simple constant regression trend.</span>
<span class="sd">            Available built-in regression models are:</span>
<span class="sd">            &#39;constant&#39;, &#39;linear&#39;</span>
<span class="sd">        theta : double, array_like or list, optional</span>
<span class="sd">            Value of correlation parameters if they are known; no optimization is run.</span>
<span class="sd">            Default is None, so that optimization is run.</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: an array with shape (n_features, ) for</span>
<span class="sd">            isotropic calculation. It is replicated for all levels.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        theta0 : double, array_like or list, optional</span>
<span class="sd">            Starting point for the maximum likelihood estimation of the</span>
<span class="sd">            best set of parameters.</span>
<span class="sd">            Default is None and meaning use of the default 0.5*np.ones(n_features)</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: an array with shape (n_features, ) for</span>
<span class="sd">            isotropic calculation. It is replicated for all levels.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        thetaL : double, array_like or list, optional</span>
<span class="sd">            Lower bound on the autocorrelation parameters for maximum</span>
<span class="sd">            likelihood estimation.</span>
<span class="sd">            Default is None meaning use of the default 1e-5*np.ones(n_features).</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: An array with shape matching theta0&#39;s. It is replicated</span>
<span class="sd">            for all levels of code.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        thetaU : double, array_like or list, optional</span>
<span class="sd">            Upper bound on the autocorrelation parameters for maximum</span>
<span class="sd">            likelihood estimation.</span>
<span class="sd">            Default is None meaning use of default value 50*np.ones(n_features).</span>
<span class="sd">            if double: value is replicated for all features and all levels.</span>
<span class="sd">            if array_like: An array with shape matching theta0&#39;s. It is replicated</span>
<span class="sd">            for all levels of code.</span>
<span class="sd">            if list: a list of nlevel arrays specifying value for each level</span>
<span class="sd">        tolerance : float</span>
<span class="sd">            Optimizer terminates when the tolerance tol is reached.</span>
<span class="sd">        initial_range : float</span>
<span class="sd">            Initial range for the optimizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiFiCoKrigingSurrogate</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_range</span> <span class="o">=</span> <span class="n">initial_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiFiCoKriging</span><span class="p">(</span><span class="n">regr</span><span class="o">=</span><span class="n">regr</span><span class="p">,</span> <span class="n">rho_regr</span><span class="o">=</span><span class="n">rho_regr</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span>
                                      <span class="n">theta0</span><span class="o">=</span><span class="n">theta0</span><span class="p">,</span> <span class="n">thetaL</span><span class="o">=</span><span class="n">thetaL</span><span class="p">,</span> <span class="n">thetaU</span><span class="o">=</span><span class="n">thetaU</span><span class="p">,</span>
                                      <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiFiCoKrigingSurrogate.predict"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKrigingSurrogate.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate a predicted value of the response based on the current trained model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_x : array_like</span>
<span class="sd">            An array with shape (n_eval, n_features) giving the point(s) at</span>
<span class="sd">            which the prediction(s) should be made.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        array_like</span>
<span class="sd">            An array with shape (n_eval, ) with the Best Linear Unbiased</span>
<span class="sd">            Prediction at X. If all_levels is set to True, an array</span>
<span class="sd">            with shape (n_eval, nlevel) giving the BLUP for all levels.</span>

<span class="sd">        array_like</span>
<span class="sd">            An array with shape (n_eval, ) with the square root of the Mean Squared Error at X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Y_pred</span><span class="p">,</span> <span class="n">MSE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">new_x</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">Y_pred</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">MSE</span><span class="p">))</span></div>

<div class="viewcode-block" id="MultiFiCoKrigingSurrogate.train_multifi"><a class="viewcode-back" href="../../../_srcdocs/packages/surrogate_models/multifi_cokriging.html#openmdao.surrogate_models.multifi_cokriging.MultiFiCoKrigingSurrogate.train_multifi">[docs]</a>    <span class="k">def</span> <span class="nf">train_multifi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the surrogate model with the given set of inputs and outputs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array_like</span>
<span class="sd">            An array with shape (n_samples_X, n_features) with the input at which observations</span>
<span class="sd">            were made.</span>
<span class="sd">        Y : array_like</span>
<span class="sd">            An array with shape (n_samples_X, n_features) with the observations of the scalar</span>
<span class="sd">            output to be predicted.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_adapter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
                       <span class="n">initial_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_range</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_fit_adapter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Manage special case with one fidelity.</span>

<span class="sd">        where can be called as [[xval1],[xval2]] instead of [[[xval1],[xval2]]]</span>
<span class="sd">        we detect if shape(X[0]) is like (m,) instead of (m, n)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array_like</span>
<span class="sd">            An array with shape (n_samples_X, n_features)</span>
<span class="sd">        Y : array_like</span>
<span class="sd">            An array with shape (n_samples_Y, n_features)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of double array_like elements</span>
<span class="sd">            A list of arrays with the input at which observations were made, from lowest</span>
<span class="sd">            fidelity to highest fidelity. Designs must be nested</span>
<span class="sd">            with X[i] = np.vstack([..., X[i+1])</span>
<span class="sd">        list of double array_like elements</span>
<span class="sd">            A list of arrays with the observations of the scalar output to be predicted,</span>
<span class="sd">            from lowest fidelity to highest fidelity.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">]</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">Y</span><span class="p">]</span>

        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">X</span><span class="p">)]</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">Y</span><span class="p">)]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">()</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">OpenMDAO 2.8.0 Beta documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, openmdao.org.
      Last updated on Aug 08, 2019.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.1.
    </div>
  </body>
</html>